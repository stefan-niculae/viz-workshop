{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_5a import parse_report, cache_locally, find_coordinates, replace_column_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapbox_access_token = open('mapbox_token.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infected map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://systems.jhu.edu/research/public-health/ncov/ inspired by this dashboard (warning: in the US only city-level counts are mapped, not unassigned locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good vid https://www.youtube.com/watch?v=9PYKYjkqnGU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data from PDF reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: [WHO](https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest reports, that respect follow (more or less) the same format\n",
    "who_reports = [\n",
    "    ('https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200219-sitrep-30-covid-19.pdf', 4, 5),\n",
    "    # 31 purposely not included\n",
    "    ('https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200221-sitrep-32-covid-19.pdf', 3, 4),\n",
    "    ('https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200222-sitrep-33-covid-19.pdf', 3, 4),\n",
    "    ('https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200223-sitrep-34-covid-19.pdf', 2, 3),\n",
    "    ('https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200224-sitrep-35-covid-19.pdf', 3, 4),\n",
    "    ('https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200225-sitrep-36-covid-19.pdf', 2, 3),\n",
    "    ('https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200226-sitrep-37-covid-19.pdf', 2, 3),\n",
    "    ('https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200227-sitrep-38-covid-19.pdf', 3, (4,5)),\n",
    "    ('https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200228-sitrep-39-covid-19.pdf', 3, (4,5)),\n",
    "    ('https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200229-sitrep-40-covid-19.pdf', 3, (4,5)),\n",
    "    ('https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200301-sitrep-41-covid-19.pdf', 3, (4,5)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open `helpers_5a.py` for parsing implementation implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.concat([parse_report(*args) for args in who_reports])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make use of pre-cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_urls = {\n",
    "    'cases':      'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv',\n",
    "    'deaths':     'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv',\n",
    "    'recovered':  'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {key: pd.read_csv(url) for key, url in dataset_urls.items()}\n",
    "dfs['cases'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_info_bak = dfs['cases'].iloc[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_info = dfs['cases'].iloc[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {key: df.iloc[:, 4:] for key, df in dfs.items()}\n",
    "dfs['cases'];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_info = region_info_bak.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_info.columns = ['state', 'country', 'lat', 'lon']\n",
    "\n",
    "# So we can later find the country code\n",
    "replace_column_values(region_info, 'country', {\n",
    "    'UK': 'United Kingdom',\n",
    "    'US': 'United States',\n",
    "    'Mainland China': 'China',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Special treatment: Diamond Princess cruise ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat the cruise ship as its own country\n",
    "cruise_row = (region_info.country == 'Others') & (region_info.state == 'Diamond Princess cruise ship')\n",
    "region_info[cruise_row] = (np.nan, 'Diamond Princess', 33.9593, 138.8067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_mask = region_info.country == 'United States'\n",
    "region_info.loc[us_mask, 'state'] = region_info[us_mask].state.str.replace(' (From Diamond Princess)', '', regex=False)  # don't care about the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus_cruise_row = (region_info.country == 'Australia') & (region_info.state == 'From Diamond Princess')\n",
    "region_info.loc[aus_cruise_row, 'state'] = 'Unassigned Location'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum country totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, count in region_info.country.value_counts().items():\n",
    "    mask = region_info.country == country\n",
    "    \n",
    "    # For Hong Kong and Macau, which both appear only once as countries but have the subdivision set to Hong Kong, Macau respectively\n",
    "    if count == 1:\n",
    "        region_info.loc[mask, 'state'] = np.nan\n",
    "        \n",
    "    else:\n",
    "        print('Adding totals for', country)\n",
    "        idx = len(region_info)  # append\n",
    "        region_info.loc[idx] = ('All', country, *find_coordinates(country))\n",
    "\n",
    "        for df in dfs.values():\n",
    "            df.loc[idx] = df[mask].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having `All` in the `state` column means the `country` has multiple states info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign standardized country names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_country_code(country_name):\n",
    "    if country_name == 'Diamond Princess':\n",
    "        return 'DP'\n",
    "    if country_name == 'South Korea':  # Republic of Korea is recognized\n",
    "        return 'KOR'\n",
    "    if country_name == 'Macau':  # Macao is recognized though\n",
    "        return 'MAC'\n",
    "    if country_name == 'Czech Republic (Czechia)':\n",
    "        country_name = 'Czech Republic'\n",
    "    \n",
    "    try:\n",
    "        return pycountry.countries.search_fuzzy(country_name)[0].alpha_3\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "region_info['country_code'] = region_info.country.map(find_country_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum state totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_state_info(url, table_number, state_abbrev_pop_columns):\n",
    "    df = pd.read_html(url)[table_number].iloc[:, state_abbrev_pop_columns]\n",
    "    df.columns = ['state', 'abbrev', 'population']\n",
    "    \n",
    "    for col in ['state', 'abbrev']:\n",
    "        df[col] = df[col].str.replace(f'\\[.*\\]', '')  # remove link brackets\n",
    "        df[col] = df[col].str.replace(f'\\[', '')  # remove link brackets\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "state_info = {\n",
    "    'USA': parse_state_info('https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States', 0, [0, 1, 5]),\n",
    "    'CAN': parse_state_info('https://en.wikipedia.org/wiki/Provinces_and_territories_of_Canada',                 1, [1, 2, 6]),\n",
    "    'AUS': parse_state_info('https://en.wikipedia.org/wiki/States_and_territories_of_Australia',                 2, [1, 4, 6]),\n",
    "    'CHN': parse_state_info('https://www.worldatlas.com/articles/chinese-provinces-by-population.html',          0, [1, 1, 2]),\n",
    "}\n",
    "state_info['CAN'] = state_info['CAN'][:-1]  # has a totals row at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_info['city'] = np.nan # or subdivision such as Orange County\n",
    "for i, row in region_info.iterrows():\n",
    "    if pd.isna(row.state):\n",
    "        continue\n",
    "    try:\n",
    "        city, state = re.match(r'(.+), ([A-Z]{2})$', row.state).groups()\n",
    "    except AttributeError:\n",
    "        continue  # no match\n",
    "\n",
    "    country_states = state_info[row.country_code]\n",
    "    state_row = country_states[country_states.abbrev == state]\n",
    "    if len(state_row) == 1:  # if it was an abbreviation\n",
    "        state = state_row.state.iloc[0]\n",
    "    print('Assigned', state, 'to', city)\n",
    "\n",
    "    region_info.loc[i, 'city'] = city\n",
    "    region_info.loc[i, 'state'] = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in region_info.state.unique():\n",
    "    cities_mask = (region_info.state == state) & (~pd.isna(region_info.city))\n",
    "    if not any(cities_mask):\n",
    "        continue\n",
    "    state_row = region_info[cities_mask].iloc[0].copy()  # pick the row for an arbitrary city\n",
    "    state_row.city = 'All'  # erase the arbitraty city name\n",
    "    state_row.lat, state_row.lon = find_coordinates(f'{state_row.state}, {state_row.country_code}')  # update coordinates of entire state\n",
    "    \n",
    "    idx = len(region_info)\n",
    "    region_info.loc[idx] = state_row\n",
    "    \n",
    "    for df in dfs.values():\n",
    "        df.loc[idx] = df[cities_mask].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having `All` in the `city` column means the `state` has data for multiple cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More specific coordiantes for known regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_info['display_subdivision'] = np.nan\n",
    "region_info.loc[region_info.state   == 'Hubei', 'display_subdivision'] = 'Wuhan'\n",
    "region_info.loc[region_info.country == 'Italy', 'display_subdivision'] = 'Milan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~region_info.display_subdivision.isna()\n",
    "region_info.loc[mask, 'lat'], region_info.loc[mask, 'lon'] = zip(*region_info[mask].display_subdivision.map(find_coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in region_info.iterrows():\n",
    "    if row.state == 'Unassigned Location':\n",
    "        region_info.loc[i, 'lat'], region_info.loc[i, 'lon'] = find_coordinates(row.country)\n",
    "        print('Placed unassigned locations in the middle of', row.country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add population data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Country level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://www.worldometers.info/world-population/population-by-country/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df = pd.read_html('https://www.worldometers.info/world-population/population-by-country/')[0]\n",
    "pop_df = pop_df[['Country (or dependency)', 'Population (2020)']].dropna()\n",
    "pop_df.columns = ['country', 'population']\n",
    "pop_df['country_code'] = pop_df.country.map(find_country_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fuzzy searching both Netherlands (population 17M), and Caribbean Netherlands (population 26k) correctly match NLD. But we will assume it is talking about the most populous region. Same for France and Reunion, and other such territories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df = pop_df\\\n",
    "    .drop('country', axis=1)\\\n",
    "    .sort_values(by='population', ascending=False)\\\n",
    "    .drop_duplicates(subset='country_code', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://en.wikipedia.org/wiki/Diamond_Princess_(ship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df.loc[len(pop_df)] = (2670 + 1100, 'DP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_info = pd.merge(region_info, pop_df, on='country_code', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### State level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this trick because no two countries in this list have the same state names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states_info = pd.concat(state_info.values())\n",
    "assert len(all_states_info) == sum(map(len, state_info.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_pop_series = pd.merge(region_info.state, all_states_info.drop('abbrev', axis=1), on='state', how='left').population\n",
    "mask = ~pd.isna(state_pop_series)  # state field is filled and the state exists in the population data (including != All)\n",
    "region_info.loc[mask, 'population'] = state_pop_series[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### City level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: could go down to city level (eg: using data from [here](https://www.worldometers.info/world-population/us-population/)) but in the US at least, the data provided sometimes comes at a county level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities_mask = ~pd.isna(region_info.city) & (region_info.city != 'All')\n",
    "# region_info.loc[cities_mask, 'population'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_info.sort_values(by=['country', 'state', 'city'], inplace=True)\n",
    "sort_indices = region_info.index\n",
    "\n",
    "for key, df in dfs.items():\n",
    "    dfs[key] = df.iloc[sort_indices].reset_index()\n",
    "    \n",
    "region_info.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.10g}'.format\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_info = region_info[['country', 'country_code', 'state', 'city', 'display_subdivision', 'lat', 'lon', 'population']]\n",
    "region_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_mask = region_info.state.isin([np.nan, 'All'])  # includes country \"Diamond Princess\"\n",
    "cities_mask = ~pd.isna(region_info.city) & (region_info.city != 'All')\n",
    "states_mask = ~countries_mask & ~cities_mask  # includes \"state\" Unassigned Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get region boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: naturalearthdata.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with urlopen('https://github.com/nvkelso/natural-earth-vector/raw/master/geojson/ne_10m_admin_0_countries.geojson') as response:\n",
    "    countries_geojson = json.load(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country_shape in countries_geojson['features']:\n",
    "    country_shape['id'] = country_shape['properties']['ADM0_A3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drew on geojson.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond_princess_shape = {\n",
    "  \"type\": \"Feature\",\n",
    "  \"properties\": {},\n",
    "  \"geometry\": {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "      [\n",
    "        [\n",
    "          138.80401611328125,\n",
    "          33.988918483762156\n",
    "        ],\n",
    "        [\n",
    "          138.77105712890625,\n",
    "          33.97297577172598\n",
    "        ],\n",
    "        [\n",
    "          138.7738037109375,\n",
    "          33.94335994657882\n",
    "        ],\n",
    "        [\n",
    "          138.7957763671875,\n",
    "          33.92740869431181\n",
    "        ],\n",
    "        [\n",
    "          138.82049560546875,\n",
    "          33.93196649986436\n",
    "        ],\n",
    "        [\n",
    "          138.83697509765625,\n",
    "          33.950195282756994\n",
    "        ],\n",
    "        [\n",
    "          138.83697509765625,\n",
    "          33.97525348507592\n",
    "        ],\n",
    "        [\n",
    "          138.80401611328125,\n",
    "          33.988918483762156\n",
    "        ]\n",
    "      ]\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "    \n",
    "diamond_princess_shape['id'] = 'DP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_geojson['features'].append(diamond_princess_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_with_shape = {shape['id'] for shape in countries_geojson['features']}\n",
    "print('Countries with missing shape:', set(region_info[countries_mask].country_code) - countries_with_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### States/provinces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maps borders are not definitive: https://www.youtube.com/watch?v=q9ZMub2UrKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with urlopen('https://github.com/nvkelso/natural-earth-vector/raw/master/geojson/ne_10m_admin_1_states_provinces.geojson') as response:\n",
    "    states_geojson = json.load(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are very many shapes, so just keep the ones that we'll work with\n",
    "countries_with_states = region_info[states_mask].country_code.unique().tolist()\n",
    "states_geojson['features'] = [shape \n",
    "                              for shape in states_geojson['features'] \n",
    "                              if shape['properties']['adm0_a3'] in countries_with_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state_shape in states_geojson['features']:\n",
    "    id_ = state_shape['properties']['woe_name'] or state_shape['properties']['name']\n",
    "    id_ = unidecode(id_)  # Québec -> Quebec\n",
    "    \n",
    "    if id_ == 'Inner Mongol':\n",
    "        id_ = 'Inner Mongolia'\n",
    "    if id_ == 'Xizang':\n",
    "        id_ = 'Tibet'\n",
    "    \n",
    "    state_shape['id'] = id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_with_shape = {shape['id'] for shape in states_geojson['features']}\n",
    "print('States with missing shape:', set(region_info[states_mask].state) - states_with_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hover text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbn(x, precision=1, threshold=.9):\n",
    "    \"\"\" readable big number \"\"\"\n",
    "    was_negative = x < 0\n",
    "    x = abs(x)\n",
    "    \n",
    "    threshold = threshold or 1\n",
    "    if x < 1_000 * threshold:\n",
    "        suffix = ''\n",
    "    elif x < 1_000_000 * threshold:\n",
    "        x /= 1_000.\n",
    "        suffix = 'k'\n",
    "    elif x < 1_000_000_000 * threshold:\n",
    "        x /= 1_000_000.\n",
    "        suffix = 'm'\n",
    "    else:\n",
    "        x /= 1_000_000_000.\n",
    "        suffix = 'b'\n",
    "        \n",
    "    fmt = '{:.' + str(precision) + 'f}'\n",
    "    nr = fmt.format(x)\n",
    "    \n",
    "    nr = nr.lstrip('0')  # remove leading zeros\n",
    "    \n",
    "    if precision > 0: # otherwise we strip useful zeros\n",
    "        nr = nr.rstrip('0').rstrip('.')  # remove trailing zeros\n",
    "\n",
    "    if nr == '':\n",
    "        return '0'\n",
    "    \n",
    "    preffix = '-' if was_negative else ''\n",
    "    return preffix + nr + suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsn(x, percentage=True):\n",
    "    \"\"\" readable small number \"\"\"\n",
    "    fmt_type = '%' if percentage else 'f'\n",
    "    if x > .01:\n",
    "        precision = 1\n",
    "    else:\n",
    "        precision = 3\n",
    "    fmt = '{:.' + str(precision) + fmt_type +'}'\n",
    "    \n",
    "    nr = fmt.format(x)\n",
    "    #nr = nr.lstrip('0')  # remove leading zeros\n",
    "    \n",
    "    nr = nr.rstrip('%')\n",
    "    nr = nr.rstrip('0').rstrip('.')  # remove trailing zeros\n",
    "    if percentage:\n",
    "        nr += '%'\n",
    "    \n",
    "    if nr.replace('%', '') == '':\n",
    "        return '0'\n",
    "    return nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hover_text(idx, row):\n",
    "    population_label = 'Population' if pd.isna(row.city) else 'State population'\n",
    "    \n",
    "    cases  = dfs['cases']    .iloc[idx, -1]\n",
    "    deaths = dfs['deaths']   .iloc[idx, -1]\n",
    "    recvd  = dfs['recovered'].iloc[idx, -1]\n",
    "    \n",
    "    cases_per = cases / row.population\n",
    "    cases_details = 'less than 0.001%' if cases_per * 100 < 0.001 else f'{rsn(cases_per, 4)}'\n",
    "    \n",
    "    deaths_paren = '' if deaths == 0 else f' ({rsn(deaths/cases)} of cases)'\n",
    "    recvd_paren  = '' if recvd  == 0 else f' ({rsn(recvd /cases)} of cases)'\n",
    "    \n",
    "    title = row.country\n",
    "    if not pd.isna(row.state) and row.state != 'All':\n",
    "        title = f'{row.state}, {title}'\n",
    "    if not pd.isna(row.city) and row.city != 'All':\n",
    "        title = f'{row.city}, {title}'\n",
    "    \n",
    "    s = (f'<b>{title}</b><br>'\n",
    "         f'{population_label}: {rbn(row.population)}<br>'\n",
    "         f'Cases: {cases:,} ({cases_details} of population)<br>'\n",
    "         f'Deaths: {deaths:,}{deaths_paren}<br>'\n",
    "         f'Recovered: {recvd:,}{recvd_paren}<br>'\n",
    "        )\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_info['hover_text'] = [build_hover_text(*t) for t in region_info.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess for density map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally (also impossibly), we would have the coordinates of each case/death, and plot them individually (achieveing a granularity level similar to [this](https://docs.mapbox.com/help/tutorials/make-a-heatmap-with-mapbox-gl-js/)). Instead, we have counts aggregated at various region levels. We will add jitter (random noise) to the default location assigned to each region (center of city/county, or state/province or country), as to simulate granularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add jitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Density map displays four (implicit) axes: vertical and horizontal axes, amount of points, and also magnitude of each point. In our case the magnitude will represent the mortality rate, also known as the case fatality rate (CFR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_without_states_mask = countries_mask & (~region_info.country_code.isin(countries_with_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_without_cities_mask = states_mask & pd.isna(region_info.city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_mask = (countries_without_states_mask | states_without_cities_mask) & (dfs['cases'].iloc[:, -1] > 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter = .2  # 1 unit degree of latitude is about 110km/69 miles (differs by latitude)\n",
    "generate_jitter = lambda mean, count: np.random.normal(mean, jitter, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_deaths = lambda i: dfs['deaths'].iloc[i, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jittered = pd.concat(\n",
    "    pd.DataFrame({\n",
    "        'lat': generate_jitter(row.lat, get_deaths(i)),\n",
    "        'lon': generate_jitter(row.lon, get_deaths(i)),\n",
    "        'z': get_deaths(i) / dfs['cases'].iloc[i, -1],\n",
    "        'hover_text': row.hover_text\n",
    "    })\n",
    "    for i, row in region_info[jitter_mask].iterrows()\n",
    "    if get_deaths(i) > 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jittered.z.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log scale for heatmap is not supported so we create it manually\n",
    "zmax_prelog = 10_000\n",
    "zmax = np.log10(zmax_prelog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickvals = np.arange(0, zmax+.001, 1)\n",
    "ticktext = 10 ** tickvals\n",
    "ticktext = [f'{v:,.0f}' for v in ticktext]\n",
    "\n",
    "ticktext[0] = '1'\n",
    "ticktext[-1] += '+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choro_options = dict(\n",
    "    marker_line=dict(\n",
    "        color='rgb(92, 4, 18)',  # brownish red\n",
    "        width=.2,\n",
    "    ),\n",
    "    \n",
    "    colorscale='Reds',\n",
    "    zauto=False,\n",
    "    zmin=1,\n",
    "    zmax=zmax,\n",
    "    colorbar=dict(\n",
    "        tickvals=tickvals,\n",
    "        ticktext=ticktext,\n",
    "        title='Cases',\n",
    "        \n",
    "        # Possible option to prevent map resizing\n",
    "#         xanchor='left',\n",
    "#         x=0,\n",
    "#         tickfont_color='white',\n",
    "    ),\n",
    "    \n",
    "    hoverinfo='text',\n",
    ")\n",
    "\n",
    "fig = go.Figure([\n",
    "    # Cities scatter\n",
    "    go.Scattermapbox(\n",
    "        below='',\n",
    "        lat=region_info[cities_mask].lat,\n",
    "        lon=region_info[cities_mask].lon,\n",
    "        \n",
    "        name='',\n",
    "        text=region_info[cities_mask].hover_text,\n",
    "        hoverinfo='text',\n",
    "\n",
    "        marker=dict(\n",
    "            color='rgb(92, 4, 18)',  # brownish red\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    # Cases choropleth\n",
    "    go.Choroplethmapbox(\n",
    "        geojson=countries_geojson, \n",
    "        locations=region_info[countries_without_states_mask].country_code, \n",
    "        z=np.log10(dfs['cases'][countries_without_states_mask].iloc[:, -1]),\n",
    "        text=region_info[countries_without_states_mask].hover_text,\n",
    "\n",
    "        **choro_options,\n",
    "    ),\n",
    "    go.Choroplethmapbox(\n",
    "        geojson=states_geojson, \n",
    "        locations=region_info[states_mask].state, \n",
    "        z=np.log10(dfs['cases'][states_mask].iloc[:, -1]),\n",
    "        text=region_info[states_mask].hover_text,\n",
    "        \n",
    "        **choro_options,\n",
    "        showscale=False,\n",
    "    ),\n",
    "    \n",
    "    # Mortality density box\n",
    "    go.Densitymapbox(\n",
    "        visible=False,\n",
    "        below='',  # place it above everything\n",
    "        \n",
    "        lat=jittered.lat, \n",
    "        lon=jittered.lon, \n",
    "        z=jittered.z,\n",
    "        text=jittered.hover_text,\n",
    "        \n",
    "        name='',\n",
    "        hovertemplate='%{text}',\n",
    "\n",
    "        radius=10,\n",
    "        colorscale='Plasma',\n",
    "\n",
    "        zauto=False, zmin=0,\n",
    "        \n",
    "        colorbar=dict(\n",
    "            title='Mortality',\n",
    "            tickformat='%.%'\n",
    "        )\n",
    "    ),\n",
    "\n",
    "\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(t=0, b=0, r=0, l=0),\n",
    "    height=800,\n",
    "    mapbox=dict(\n",
    "        accesstoken=mapbox_access_token,\n",
    "        style='light',  # carto-positron also works well and requires no key\n",
    "    ),\n",
    "    \n",
    "    \n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type='buttons',\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    args=[dict(visible=[True, True, True, False])],\n",
    "                    label='Cases',\n",
    "                    method='update'\n",
    "                ),\n",
    "                dict(\n",
    "                    args=[dict(visible=[True, False, False, True])],\n",
    "                    label='Mortality',\n",
    "                    method='update'\n",
    "                )\n",
    "            ],\n",
    "\n",
    "            pad=dict(t=10),\n",
    "            direction='left',\n",
    "\n",
    "            x=0,\n",
    "            xanchor='left',\n",
    "\n",
    "            y=1.07,\n",
    "            yanchor='top',\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    " - slider & animation over time\n",
    " - per country bar plot to the side with time increments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: division by zero happens when the cases count is zero. The data contains zeros because at the requested date, there are zero cases. The resulting behavior is correct: a `NaN` value is not plotted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At higher zoom levels, the intensity of the color indicates the (absolute) amount of deaths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caveat: numbers are not precise, especially in China, which changed the definition of a \"confirmed\" case several times [source](https://www.nytimes.com/interactive/2020/world/coronavirus-maps.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viz-workshop-2020",
   "language": "python",
   "name": "viz-workshop-2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
